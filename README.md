# stat453-deep-learning-ss21
STAT 453: Intro to Deep Learning @ UW-Madison (Spring 2021)

| Lectures | Code |
|----------|------|
| [L1.0 Intro to Deep Learning, Course Introduction](https://www.youtube.com/watch?v=1nqCZqDYPp0) | [code](./L01) |
| [L1.1.1 Course Overview Part 1: Motivation and Topics](https://www.youtube.com/watch?v=6VbtJ9nn5ng) | [code](./L01) |
| [L1.1.2 Course Overview Part 2: Organization (Optional)](https://www.youtube.com/watch?v=s7ZCbKI5Exw) | [code](./L01) |
| [L1.2 What is Machine Learning?](https://www.youtube.com/watch?v=d6oQzE4kst0) | [code](./L01) |
| [L1.3.1 Broad Categories of ML Part 1: Supervised Learning](https://www.youtube.com/watch?v=UadzJLHJB50) | [code](./L01) |
| [L1.3.2 Broad Categories of ML Part 2: Unsupervised Learning](https://www.youtube.com/watch?v=nHhuuUwd05g) | [code](./L01) |
| [L1.3.3 Broad Categories of ML Part 3: Reinforcement Learning](https://www.youtube.com/watch?v=EQCZUOxGrOo) | [code](./L01) |
| [L1.3.4 Broad Categories of ML Part 4: Special Cases of Supervised Learning](https://www.youtube.com/watch?v=B59lK5yo57M) | [code](./L01) |
| [L1.4 The Supervised Learning Workflow](https://www.youtube.com/watch?v=nd9dhrvtIA0) | [code](./L01) |
| [L1.5 Necessary Machine Learning Notation and Jargon](https://www.youtube.com/watch?v=o-yHLOvuh2o) | [code](./L01) |
| [L1.6 About the Practical Aspects and Tools Used in This Course](https://www.youtube.com/watch?v=R16VmI2ZhR0) | [code](./L01) |
| [L2.0 A Brief History of Deep Learning -- Lecture Overview](https://www.youtube.com/watch?v=Ezig00nypvU) | [code](./L02) |
| [L2.1 Artificial Neurons](https://www.youtube.com/watch?v=gbLasjwAGik) | [code](./L02) |
| [L2.2 Multilayer Networks](https://www.youtube.com/watch?v=G7oqVqU5qsQ) | [code](./L02) |
| [L2.3 The Origins of Deep Learning](https://www.youtube.com/watch?v=tkUCMtJd43Y) | [code](./L02) |
| [L2.4 The Deep Learning Hardware &amp; Software Landscape](https://www.youtube.com/watch?v=TMCNkeJGIfg) | [code](./L02) |
| [L2.5 Current Trends in Deep Learning](https://www.youtube.com/watch?v=FpOpb-BMIH8) | [code](./L02) |
| [L3.0 Perceptron Lecture Overview](https://www.youtube.com/watch?v=cm_wv2QpTgc) | [code](./L03) |
| [L3.1 About Brains and Neurons](https://www.youtube.com/watch?v=AnSDPcvtRLo) | [code](./L03) |
| [L3.2 The Perceptron Learning Rule](https://www.youtube.com/watch?v=C8Uns9HEVXI) | [code](./L03) |
| [L3.3 Vectorization in Python](https://www.youtube.com/watch?v=OnG2NfuC5aY) | [code](./L03) |
| [L3.4 Perceptron in Python using NumPy and PyTorch](https://www.youtube.com/watch?v=TlGpIKMVoOg) | [code](./L03) |
| [L3.5 The Geometric Intuition Behind the Perceptron](https://www.youtube.com/watch?v=Fj7BgxI73TA) | [code](./L03) |
| [L4.0 Linear Algebra for Deep Learning -- Lecture Overview](https://www.youtube.com/watch?v=3mjJxu3B0zA) | [code](./L04) |
| [L4.1 Tensors in Deep Learning](https://www.youtube.com/watch?v=JXfDlgrfOBY) | [code](./L04) |
| [L4.2 Tensors in PyTorch](https://www.youtube.com/watch?v=zk_asBov8QI) | [code](./L04) |
| [L4.3 Vectors, Matrices, and Broadcasting](https://www.youtube.com/watch?v=4Ehb_is-MFU) | [code](./L04) |
| [L4.4 Notational Conventions for Neural Networks](https://www.youtube.com/watch?v=4pnoymfFiYM) | [code](./L04) |
| [L4.5 A Fully Connected (Linear) Layer in PyTorch](https://www.youtube.com/watch?v=XswEBzNgIYc) | [code](./L04) |
| [L5.0 Gradient Descent -- Lecture Overview](https://www.youtube.com/watch?v=VBOxg62CwCg) | [code](./L05) |
| [L5.1 Online, Batch, and Minibatch Mode](https://www.youtube.com/watch?v=b4DXHd3RwqA) | [code](./L05) |
| [L5.2 Relation Between Perceptron and Linear Regression](https://www.youtube.com/watch?v=4JB1j8eIGzI) | [code](./L05) |
| [L5.3 An Iterative Training Algorithm for Linear Regression](https://www.youtube.com/watch?v=1QH2bVuV98A) | [code](./L05) |
| [L5.4 (Optional) Calculus Refresher I: Derivatives](https://www.youtube.com/watch?v=tL1THESrXgI) | [code](./L05) |
| [L5.5 (Optional) Calculus Refresher II: Gradients](https://www.youtube.com/watch?v=YPZVGSRmjLk) | [code](./L05) |
| [L5.6 Understanding Gradient Descent](https://www.youtube.com/watch?v=L4xzybIa-bo) | [code](./L05) |
| [L5.7 Training an Adaptive Linear Neuron (Adaline)](https://www.youtube.com/watch?v=iLCT0i-lCsw) | [code](./L05) |
| [L5.8 Adaline Code Example](https://www.youtube.com/watch?v=GGcaqzhKzLc) | [code](./L05) |
| [L6.0 Automatic Differentiation in PyTorch -- Lecture Overview](https://www.youtube.com/watch?v=j1-r1vO2a_o) | [code](./L06) |
| [L6.1 Learning More About PyTorch](https://www.youtube.com/watch?v=LjdiVPQ45GE) | [code](./L06) |
| [L6.2 Understanding Automatic Differentiation via Computation Graphs](https://www.youtube.com/watch?v=oY6-i2Ybin4) | [code](./L06) |
| [L6.3 Automatic Differentiation in PyTorch -- Code Example](https://www.youtube.com/watch?v=VvUz0Q9e09g) | [code](./L06) |
| [L6.4 Training ADALINE with PyTorch -- Code Example](https://www.youtube.com/watch?v=00KgeJwNaZA) | [code](./L06) |
| [L6.5 A Closer Look at the PyTorch API](https://www.youtube.com/watch?v=klc79sZ1yVc) | [code](./L06) |
| [L7.0 GPU resources &amp; Google Colab](https://www.youtube.com/watch?v=5pew4YEa1ww) | [code](./L07) |
| [L8.0 Logistic Regression -- Lecture Overview](https://www.youtube.com/watch?v=10PTpRRpRk0) | [code](./L08) |
| [L8.1 Logistic Regression as a Single-Layer Neural Network](https://www.youtube.com/watch?v=ncZ5iSZekVQ) | [code](./L08) |
| [L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM) | [code](./L08) |
| [L8.3 Logistic Regression Loss Derivative and Training](https://www.youtube.com/watch?v=7rR1L7t2EnA) | [code](./L08) |
| [L8.4 Logits and Cross Entropy](https://www.youtube.com/watch?v=icQaFxKa_J0) | [code](./L08) |
| [L8.5 Logistic Regression in PyTorch -- Code Example](https://www.youtube.com/watch?v=6igMArA6k3A) | [code](./L08) |
| [L8.6 Multinomial Logistic Regression / Softmax Regression](https://www.youtube.com/watch?v=L0FU8NFpx4E) | [code](./L08) |
| [L8.7.1 OneHot Encoding and Multi-category Cross Entropy](https://www.youtube.com/watch?v=4n71-tZ94yk) | [code](./L08) |
| [L8.7.2 OneHot Encoding and Multi-category Cross Entropy -- Code Example](https://www.youtube.com/watch?v=5bW0vn4ISqs) | [code](./L08) |
| [L8.8 Softmax Regression Derivatives for Gradient Descent](https://www.youtube.com/watch?v=aeM-fmcdkXU) | [code](./L08) |
| [L8.9 Softmax Regression -- Code Example Using PyTorch](https://www.youtube.com/watch?v=mM6apVBXGEA) | [code](./L08) |
| [L9.0 Multilayer Perceptrons -- Lecture Overview](https://www.youtube.com/watch?v=jD6IKpqSJM4) | [code](./L09) |
| [L9.1 Multilayer Perceptron Architecture](https://www.youtube.com/watch?v=IUylp47hNA0) | [code](./L09) |
| [L9.2 Nonlinear Activation Functions](https://www.youtube.com/watch?v=-_7W0KE8Ykg) | [code](./L09) |
| [L9.3.1 Multilayer Perceptron -- Code Example Part 1/3 (Slide Overview)](https://www.youtube.com/watch?v=zNyEzACInRg) | [code](./L09) |
| [L9.3.2 Multilayer Perceptron in PyTorch -- Code Example Part 2/3 (Jupyter Notebook)](https://www.youtube.com/watch?v=Ycp4Si89s5Q) | [code](./L09) |
| [L9.3.3 Multilayer Perceptron in PyTorch -- Code Example Part 3/3 (Script Setup)](https://www.youtube.com/watch?v=cDbQgQv_Yz0) | [code](./L09) |
| [L9.4 Overfitting and Underfitting](https://www.youtube.com/watch?v=hFGZyDVNgS4) | [code](./L09) |
| [L9.5.1 Cats &amp; Dogs and Custom Data Loaders](https://www.youtube.com/watch?v=RQIAmvElu1g) | [code](./L09) |
| [L9.5.2 Custom DataLoaders in PyTorch --Code Example](https://www.youtube.com/watch?v=hPzJ8H0Jtew) | [code](./L09) |
| [L10.0 Regularization Methods for Neural Networks -- Lecture Overview](https://www.youtube.com/watch?v=Va4K-wYh_p8) | [code](./L10) |
| [L10.1 Techniques for Reducing Overfitting](https://www.youtube.com/watch?v=KOBmBjlMVAE) | [code](./L10) |
| [L10.2 Data Augmentation in PyTorch](https://www.youtube.com/watch?v=qLIosWyrh9Q) | [code](./L10) |
| [L10.3 Early Stopping](https://www.youtube.com/watch?v=YA1OdkiHJBY) | [code](./L10) |
| [L10.4 L2 Regularization for Neural Nets](https://www.youtube.com/watch?v=uu2X47cSLmM) | [code](./L10) |
| [L10.5.1 The Main Concept Behind Dropout](https://www.youtube.com/watch?v=IHrZNBsgtwU) | [code](./L10) |
| [L10.5.2 Dropout Co-Adaptation Interpretation](https://www.youtube.com/watch?v=GAE8dpDWo6E) | [code](./L10) |
| [L10.5.3 (Optional) Dropout Ensemble Interpretation](https://www.youtube.com/watch?v=4We9G5jgKvI) | [code](./L10) |
| [L10.5.4 Dropout in PyTorch](https://www.youtube.com/watch?v=kma-4wqp_-k) | [code](./L10) |
| [L11.0 Input Normalization and Weight Initialization -- Lecture Overview](https://www.youtube.com/watch?v=xk6qb2IePaE) | [code](./L11) |
| [L11.1  Input Normalization](https://www.youtube.com/watch?v=jzJactQXFDk) | [code](./L11) |
| [L11.2 How BatchNorm Works](https://www.youtube.com/watch?v=34PDIFvvESc) | [code](./L11) |
| [L11.3 BatchNorm in PyTorch -- Code Example](https://www.youtube.com/watch?v=8AUDn7iF2DY) | [code](./L11) |
| [L11.4 Why BatchNorm Works](https://www.youtube.com/watch?v=uI19wIdzh9M) | [code](./L11) |
| [L11.5 Weight Initialization -- Why Do We Care?](https://www.youtube.com/watch?v=RsX01aYbQdI) | [code](./L11) |
| [L11.6 Xavier Glorot and Kaiming He Initialization](https://www.youtube.com/watch?v=ScWTYHQra5E) | [code](./L11) |
| [L11.7 Weight Initialization in PyTorch -- Code Example](https://www.youtube.com/watch?v=nA6oEAE9IVc) | [code](./L11) |
| [L12.0: Improving Gradient Descent-based Optimization -- Lecture Overview](https://www.youtube.com/watch?v=7RhNXYqDBfU) | [code](./L12) |
| [L12.1 Learning Rate Decay](https://www.youtube.com/watch?v=Owm1H0ukjS4) | [code](./L12) |
| [L12.2 Learning Rate Schedulers in PyTorch](https://www.youtube.com/watch?v=tB1rz4L93JA) | [code](./L12) |
| [L12.3 SGD with Momentum](https://www.youtube.com/watch?v=gMxvefj0YAM) | [code](./L12) |
| [L12.4 Adam: Combining Adaptive Learning Rates and Momentum](https://www.youtube.com/watch?v=eUOvUIRPSX8) | [code](./L12) |
| [L12.5 Choosing Different Optimizers in PyTorch](https://www.youtube.com/watch?v=c-SRPvK_zzs) | [code](./L12) |
| [L12.6 Additional Topics and Research on Optimization Algorithms](https://www.youtube.com/watch?v=7yoAocFiUh8) | [code](./L12) |
| [L13.0 Introduction to Convolutional Networks -- Lecture Overview](https://www.youtube.com/watch?v=i-Ngb6tn_KM) | [code](./L13) |
| [L13.1 Common Applications of CNNs](https://www.youtube.com/watch?v=I5B7pgSEMhE) | [code](./L13) |
| [L13.2 Challenges of Image Classification](https://www.youtube.com/watch?v=0FtJbmuUdFo) | [code](./L13) |
| [L13.3 Convolutional Neural Network Basics](https://www.youtube.com/watch?v=7fWOE-z8YgY) | [code](./L13) |
| [L13.4 Convolutional Filters and Weight-Sharing](https://www.youtube.com/watch?v=ryJ6Bna-ZNU) | [code](./L13) |
| [L13.5 Cross-correlation vs. Convolution (Old)](https://www.youtube.com/watch?v=ICWHhxox1ho) | [code](./L13) |
| [L13.5 What's The Difference Between Cross-Correlation And Convolution?](https://www.youtube.com/watch?v=xbO-iIzkBy0) | [code](./L13) |
| [L13.6 CNNs &amp; Backpropagation](https://www.youtube.com/watch?v=-SwKNK9MIUU) | [code](./L13) |
| [L13.7 CNN Architectures &amp; AlexNet](https://www.youtube.com/watch?v=-IHxe4-09e4) | [code](./L13) |
| [L13.8 What a CNN Can See](https://www.youtube.com/watch?v=PRFP5YC3u7g) | [code](./L13) |
| [L13.9.1 LeNet-5 in PyTorch](https://www.youtube.com/watch?v=ye5k82FQC7I) | [code](./L13) |
| [L13.9.2 Saving and Loading Models in PyTorch](https://www.youtube.com/watch?v=vB_Y04gsyBI) | [code](./L13) |
| [L13.9.3 AlexNet in PyTorch](https://www.youtube.com/watch?v=mlXRVuD_HEg) | [code](./L13) |
| [L14.0: Convolutional Neural Networks Architectures -- Lecture Overview](https://www.youtube.com/watch?v=1A6HViSXaqQ) | [code](./L14) |
| [L14.1: Convolutions and Padding](https://www.youtube.com/watch?v=6v05kAtV1M0) | [code](./L14) |
| [L14.2: Spatial Dropout and BatchNorm](https://www.youtube.com/watch?v=TGqqTgn4cAg) | [code](./L14) |
| [L14.3: Architecture Overview](https://www.youtube.com/watch?v=WyXO762G2_A) | [code](./L14) |
| [L14.3.1.1 VGG16 Overview](https://www.youtube.com/watch?v=YcmNIOyfdZQ) | [code](./L14) |
| [L14.3.1.2 VGG16 in PyTorch -- Code Example](https://www.youtube.com/watch?v=PlFiRPdBEAo) | [code](./L14) |
| [L14.3.2.1 ResNet Overview](https://www.youtube.com/watch?v=q_IlqYlYhlo) | [code](./L14) |
| [L14.3.2.2 ResNet-34 in PyTorch -- Code Example](https://www.youtube.com/watch?v=JG_ODvnlgjY) | [code](./L14) |
| [L14.4.1 Replacing Max-Pooling with Convolutional Layers](https://www.youtube.com/watch?v=Lq83NFkkJCk) | [code](./L14) |
| [L14.4.2 All-Convolutional Network in PyTorch -- Code Example](https://www.youtube.com/watch?v=A5dC5yuPXwo) | [code](./L14) |
| [L14.5 Convolutional Instead of Fully Connected Layers](https://www.youtube.com/watch?v=rqLjZ8k4va8) | [code](./L14) |
| [L14.6.1 Transfer Learning](https://www.youtube.com/watch?v=OkQRtm9JY1k) | [code](./L14) |
| [L14.6.2 Transfer Learning in PyTorch -- Code Example](https://www.youtube.com/watch?v=FaW9JCSJn2s) | [code](./L14) |
| [L15.0: Introduction to Recurrent Neural Networks -- Lecture Overview](https://www.youtube.com/watch?v=q5YxK17tRm0) | [code](./L15) |
| [L15.1: Different Methods for Working With Text Data](https://www.youtube.com/watch?v=kwmZtkzB4e0) | [code](./L15) |
| [L15.2 Sequence Modeling with RNNs](https://www.youtube.com/watch?v=5fdy-hBeWCI) | [code](./L15) |
| [L15.3 Different Types of Sequence Modeling Tasks](https://www.youtube.com/watch?v=Ed8GTvkzkZE) | [code](./L15) |
| [L15.4 Backpropagation Through Time Overview](https://www.youtube.com/watch?v=0XdPIqi0qpg) | [code](./L15) |
| [L15.5 Long Short-Term Memory](https://www.youtube.com/watch?v=k6fSgUaWUF8) | [code](./L15) |
| [L15.6 RNNs for Classification: A Many-to-One Word RNN](https://www.youtube.com/watch?v=TI4HRR3Hd9A) | [code](./L15) |
| [L15.7 An RNN Sentiment Classifier in PyTorch](https://www.youtube.com/watch?v=KgrdifrlDxg) | [code](./L15) |
| [L16.0 Introduction to Autoencoders -- Lecture Overview](https://www.youtube.com/watch?v=9Ujv_IoBtF4) | [code](./L16) |
| [L16.1 Dimensionality Reduction](https://www.youtube.com/watch?v=UgOHupaIfcA) | [code](./L16) |
| [L16.2 A Fully-Connected Autoencoder](https://www.youtube.com/watch?v=8O_FDPIlj1s) | [code](./L16) |
| [L16.3 Convolutional Autoencoders &amp; Transposed Convolutions](https://www.youtube.com/watch?v=ilkSwsggSNM) | [code](./L16) |
| [L16.4 A Convolutional Autoencoder in PyTorch -- Code Example](https://www.youtube.com/watch?v=345wRyqKkQ0) | [code](./L16) |
| [L16.5 Other Types of Autoencoders](https://www.youtube.com/watch?v=FPZeRM1p1ao) | [code](./L16) |
| [L17.0 Intro to Variational Autoencoders -- Lecture Overview](https://www.youtube.com/watch?v=UnImUYOdWgk) | [code](./L17) |
| [L17.1 Variational Autoencoder Overview](https://www.youtube.com/watch?v=H2XgdND0DV4) | [code](./L17) |
| [L17.2 Sampling from a Variational Autoencoder](https://www.youtube.com/watch?v=YgSWrafXI8U) | [code](./L17) |
| [L17.3 The Log-Var Trick](https://www.youtube.com/watch?v=pmvo0S3-G-I) | [code](./L17) |
| [L17.4 Variational Autoencoder Loss Function](https://www.youtube.com/watch?v=ywYuZrLENH0) | [code](./L17) |
| [L17.5 A Variational Autoencoder for Handwritten Digits in PyTorch -- Code Example](https://www.youtube.com/watch?v=afNuE5z2CQ8) | [code](./L17) |
| [L17.6 A Variational Autoencoder for Face Images in PyTorch -- Code Example](https://www.youtube.com/watch?v=sul2ExoUrnw) | [code](./L17) |
| [L17.7 VAE Latent Space Arithmetic in PyTorch -- Making People Smile (Code Example)](https://www.youtube.com/watch?v=EfFr87ARDF0) | [code](./L17) |
| [L18.0: Introduction to Generative Adversarial Networks -- Lecture Overview](https://www.youtube.com/watch?v=OnoPaZaKoS8) | [code](./L18) |
| [L18.1: The Main Idea Behind GANs](https://www.youtube.com/watch?v=-Zi5SReze6U) | [code](./L18) |
| [L18.2: The GAN Objective](https://www.youtube.com/watch?v=m_H6viKCTEE) | [code](./L18) |
| [L18.3: Modifying the GAN Loss Function for Practical Use](https://www.youtube.com/watch?v=ILpC3b-819Q) | [code](./L18) |
| [L18.4: A GAN for Generating Handwritten Digits in PyTorch -- Code Example](https://www.youtube.com/watch?v=cTlxZ1FO1mY) | [code](./L18) |
| [L18.5: Tips and Tricks to Make GANs Work](https://www.youtube.com/watch?v=_cUdjPdbldQ) | [code](./L18) |
| [L18.6: A DCGAN for Generating Face Images in PyTorch -- Code Example](https://www.youtube.com/watch?v=5fs9PMzrVig) | [code](./L18) |
| [L19.0 RNNs &amp; Transformers for Sequence-to-Sequence Modeling -- Lecture Overview](https://www.youtube.com/watch?v=DlWTTrHa8bI) | [code](./L19) |
| [L19.1 Sequence Generation with Word and Character RNNs](https://www.youtube.com/watch?v=fSBw6TrePPg) | [code](./L19) |
| [L19.2.1 Implementing a Character RNN in PyTorch (Concepts)](https://www.youtube.com/watch?v=PFcWQkGP4lU) | [code](./L19) |
| [L19.2.2 Implementing a Character RNN in PyTorch --Code Example](https://www.youtube.com/watch?v=tL5puCeDr-o) | [code](./L19) |
| [L19.3 RNNs with an Attention Mechanism](https://www.youtube.com/watch?v=mDZil99CtSU) | [code](./L19) |
| [L19.4.1 Using Attention Without the RNN -- A Basic Form of Self-Attention](https://www.youtube.com/watch?v=i_pfHD4P_wg) | [code](./L19) |
| [L19.4.2 Self-Attention and Scaled Dot-Product Attention](https://www.youtube.com/watch?v=0PjHri8tc1c) | [code](./L19) |
| [L19.4.3 Multi-Head Attention](https://www.youtube.com/watch?v=A1eUVxscNq8) | [code](./L19) |
| [L19.5.1 The Transformer Architecture](https://www.youtube.com/watch?v=tstbZXNCfLY) | [code](./L19) |
| [L19.5.2.1 Some Popular Transformer Models: BERT, GPT, and BART -- Overview](https://www.youtube.com/watch?v=iFhYwEi03Ew) | [code](./L19) |
| [L19.5.2.2 GPT-v1: Generative Pre-Trained Transformer](https://www.youtube.com/watch?v=LOCzBgSV4tQ) | [code](./L19) |
| [L19.5.2.3 BERT: Bidirectional Encoder Representations from Transformers](https://www.youtube.com/watch?v=_BFp4kjSB-I) | [code](./L19) |
| [L19.5.2.4 GPT-v2: Language Models are Unsupervised Multitask Learners](https://www.youtube.com/watch?v=BXv1m9Asl7I) | [code](./L19) |
| [L19.5.2.5 GPT-v3: Language Models are Few-Shot Learners](https://www.youtube.com/watch?v=wYdKn-X4MhY) | [code](./L19) |
| [L19.5.2.6 BART:  Combining Bidirectional and Auto-Regressive Transformers](https://www.youtube.com/watch?v=1JBMCG8rW18) | [code](./L19) |
| [L19.5.2.7: Closing Words -- The Recent Growth of Language Transformers](https://www.youtube.com/watch?v=OyqIuxMmLRg) | [code](./L19) |
| [L19.6 DistilBert Movie Review Classifier in PyTorch -- Code Example](https://www.youtube.com/watch?v=emDmznRlsWw) | [code](./L19) |

# Resources

 * [Scientific Computing in Python: Introduction to NumPy and Matplotlib](https://sebastianraschka.com/blog/2020/numpy-intro.html)
